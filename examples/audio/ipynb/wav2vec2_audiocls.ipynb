{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7u8hYFgkyai"
      },
      "source": [
        "# Audio Classification with Hugging Face Transformers\n",
        "\n",
        "**Author:** Sreyan Ghosh<br>\n",
        "**Date created:** 2022/07/01<br>\n",
        "**Last modified:** 2022/08/27<br>\n",
        "**Description:** Training Wav2Vec 2.0 using Hugging Face Transformers for Audio Classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMhupewkyak"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Identification of speech commands, also known as *keyword spotting* (KWS),\n",
        "is important from an engineering perspective for a wide range of applications,\n",
        "from indexing audio databases and indexing keywords, to running speech models locally\n",
        "on microcontrollers. Currently, many human-computer interfaces (HCI) like Google\n",
        "Assistant, Microsoft Cortana, Amazon Alexa, Apple Siri and others rely on keyword\n",
        "spotting. There is a significant amount of research in the field by all major companies,\n",
        "notably Google and Baidu.\n",
        "\n",
        "In the past decade, deep learning has led to significant performance\n",
        "gains on this task. Though low-level audio features extracted from raw audio like MFCC or\n",
        "mel-filterbanks have been used for decades, the design of these low-level features\n",
        "are [flawed by biases](https://arxiv.org/abs/2101.08596). Moreover, deep learning models\n",
        "trained on these low-level features can easily overfit to noise or signals irrelevant to the\n",
        "task.  This makes it is essential for any system to learn speech representations that make\n",
        "high-level information, such as acoustic and linguistic content, including phonemes,\n",
        "words, semantic meanings, tone, speaker characteristics from speech signals available to\n",
        "solve the downstream task. [Wav2Vec 2.0](https://arxiv.org/abs/2006.11477), which solves a\n",
        "self-supervised contrastive learning task to learn high-level speech representations,\n",
        "provides a great alternative to traditional low-level features for training deep learning\n",
        "models for KWS.\n",
        "\n",
        "In this notebook, we train the Wav2Vec 2.0 (base) model, built on the\n",
        "Hugging Face Transformers library, in an end-to-end fashion on the keyword spotting task and\n",
        "achieve state-of-the-art results on the Google Speech Commands Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w006f3Mkyak"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8CMkWSYkyal"
      },
      "source": [
        "### Installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jupyter\n"
      ],
      "metadata": {
        "id": "hHWaq5-C_G98",
        "outputId": "cf583d25-a239-4607-dcf2-21da1e0c3f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter)\n",
            "  Downloading jupyterlab-4.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter) (2.18.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (75.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter) (4.3.7)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter) (4.13.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.4.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, json5, jedi, fqdn, async-lru, jupyter-server-terminals, jupyter-client, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.0 jupyterlab-server-2.27.3 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6gLBuz_kyal",
        "outputId": "dbe6798a-b765-42c3-dc9b-f4af7d1227fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-2x1tmzq1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-2x1tmzq1\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 953196a43dae6a3c474165fba7d215fcbc7b7730\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2025.1.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install huggingface-hub\n",
        "!pip install joblib\n",
        "!pip install librosa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPMy7rWkyam"
      },
      "source": [
        "### Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0uv9SsaFkyam"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Only log error messages\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "# Set random seed\n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAROKM1Okyam"
      },
      "source": [
        "### Define certain variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DDslyqfdkyan"
      },
      "outputs": [],
      "source": [
        "# Maximum duration of the input audio file we feed to our Wav2Vec 2.0 model.\n",
        "MAX_DURATION = 1\n",
        "# Sampling rate is the number of samples of audio recorded every second\n",
        "SAMPLING_RATE = 16000\n",
        "BATCH_SIZE = 32  # Batch-size for training and evaluating our model.\n",
        "NUM_CLASSES = 10  # Number of classes our dataset will have (11 in our case).\n",
        "HIDDEN_DIM = 768  # Dimension of our model output (768 in case of Wav2Vec 2.0 - Base).\n",
        "MAX_SEQ_LENGTH = MAX_DURATION * SAMPLING_RATE  # Maximum length of the input audio file.\n",
        "# Wav2Vec 2.0 results in an output frequency with a stride of about 20ms.\n",
        "MAX_FRAMES = 49\n",
        "MAX_EPOCHS = 2  # Maximum number of training epochs.\n",
        "\n",
        "MODEL_CHECKPOINT = \"facebook/wav2vec2-base\"  # Name of pretrained model from Hugging Face Model Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKkDn4eukyan"
      },
      "source": [
        "## Load the Google Speech Commands Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-oe0S_Hkyan"
      },
      "source": [
        "We now download the [Google Speech Commands V1 Dataset](https://arxiv.org/abs/1804.03209),\n",
        "a popular benchmark for training and evaluating deep learning models built for solving the KWS task.\n",
        "The dataset consists of a total of 60,973 audio files, each of 1 second duration,\n",
        "divided into ten classes of keywords (\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\",\n",
        "\"Off\", \"Stop\", and \"Go\"), a class for silence, and an unknown class to include the false\n",
        "positive. We load the dataset from [Hugging Face Datasets](https://github.com/huggingface/datasets).\n",
        "This can be easily done with the `load_dataset` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxaP6tFTkyan",
        "outputId": "b1b2ad4e-a6d1-4bb1-f4a4-8aff97efd0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "speech_commands_v1 = load_dataset(\"superb\", \"ks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZofCVnIkyan"
      },
      "source": [
        "The dataset has the following fields:\n",
        "\n",
        "- **file**: the path to the raw .wav file of the audio\n",
        "- **audio**: the audio file sampled at 16kHz\n",
        "- **label**: label ID of the audio utterance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atJzhiFCkyan",
        "outputId": "16626a59-5ccf-472a-d50e-ee80aee6a75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['file', 'audio', 'label'],\n",
            "        num_rows: 51094\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['file', 'audio', 'label'],\n",
            "        num_rows: 6798\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['file', 'audio', 'label'],\n",
            "        num_rows: 3081\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(speech_commands_v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B34P-vqOkyao"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Q3nmGgkyao"
      },
      "source": [
        "For the sake of demonstrating the workflow, in this notebook we only take\n",
        "small stratified balanced splits (50%) of the train as our training and test sets.\n",
        "We can easily split the dataset using the `train_test_split` method which expects\n",
        "the split size and the name of the column relative to which you want to stratify.\n",
        "\n",
        "Post splitting the dataset, we remove the `unknown` and `silence` classes and only\n",
        "focus on the ten main classes. The `filter` method does that easily for you.\n",
        "\n",
        "Next we sample our train and test splits to a multiple of the `BATCH_SIZE` to\n",
        "facilitate smooth training and inference. You can achieve that using the `select`\n",
        "method which expects the indices of the samples you want to keep. Rest all are\n",
        "discarded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw7ae32Ukyao",
        "outputId": "528ea6c8-a3f8-44ff-faa8-87fea2a45553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['file', 'audio', 'label'],\n",
            "        num_rows: 25536\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['file', 'audio', 'label'],\n",
            "        num_rows: 25536\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "speech_commands_v1 = speech_commands_v1[\"train\"].train_test_split(\n",
        "    train_size=0.5, test_size=0.5, stratify_by_column=\"label\"\n",
        ")\n",
        "\n",
        "speech_commands_v1 = speech_commands_v1.filter(\n",
        "    lambda x: x[\"label\"]\n",
        "    != (\n",
        "        speech_commands_v1[\"train\"].features[\"label\"].names.index(\"_unknown_\")\n",
        "        and speech_commands_v1[\"train\"].features[\"label\"].names.index(\"_silence_\")\n",
        "    )\n",
        ")\n",
        "\n",
        "speech_commands_v1[\"train\"] = speech_commands_v1[\"train\"].select(\n",
        "    [i for i in range((len(speech_commands_v1[\"train\"]) // BATCH_SIZE) * BATCH_SIZE)]\n",
        ")\n",
        "speech_commands_v1[\"test\"] = speech_commands_v1[\"test\"].select(\n",
        "    [i for i in range((len(speech_commands_v1[\"test\"]) // BATCH_SIZE) * BATCH_SIZE)]\n",
        ")\n",
        "\n",
        "print(speech_commands_v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amS-sjrBkyao"
      },
      "source": [
        "Additionally, you can check the actual labels corresponding to each label ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CXEvVrLkyao",
        "outputId": "f9a11327-d001-42f6-a318-c7e58533e98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 'yes', '1': 'no', '2': 'up', '3': 'down', '4': 'left', '5': 'right', '6': 'on', '7': 'off', '8': 'stop', '9': 'go', '10': '_silence_', '11': '_unknown_'}\n"
          ]
        }
      ],
      "source": [
        "labels = speech_commands_v1[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY8yYU-dkyao"
      },
      "source": [
        "Before we can feed the audio utterance samples to our model, we need to\n",
        "pre-process them. This is done by a Hugging Face Transformers \"Feature Extractor\"\n",
        "which will (as the name indicates) re-sample your inputs to the sampling rate\n",
        "the model expects (in-case they exist with a different sampling rate), as well\n",
        "as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we instantiate our `Feature Extractor` with the\n",
        "`AutoFeatureExtractor.from_pretrained`, which will ensure:\n",
        "\n",
        "We get a `Feature Extractor` that corresponds to the model architecture we want to use.\n",
        "We download the config that was used when pretraining this specific checkpoint.\n",
        "This will be cached so that it's not downloaded again the next time we run the cell.\n",
        "\n",
        "The `from_pretrained()` method expects the name of a model from the Hugging Face Hub. This is\n",
        "exactly similar to `MODEL_CHECKPOINT` and we just pass that.\n",
        "\n",
        "We write a simple function that helps us in the pre-processing that is compatible\n",
        "with Hugging Face Datasets. To summarize, our pre-processing function should:\n",
        "\n",
        "- Call the audio column to load and if necessary resample the audio file.\n",
        "- Check the sampling rate of the audio file matches the sampling rate of the audio data a\n",
        "model was pretrained with. You can find this information on the Wav2Vec 2.0 model card.\n",
        "- Set a maximum input length so longer inputs are batched without being truncated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m4Cv8Njkyao",
        "outputId": "afd48468-7d36-498e-eaf1-7615277f2b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoFeatureExtractor\n",
        "import gc\n",
        "\n",
        "# Initialize the feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
        "    MODEL_CHECKPOINT, return_attention_mask=True\n",
        ")\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays,\n",
        "        sampling_rate=feature_extractor.sampling_rate,\n",
        "        max_length=MAX_SEQ_LENGTH,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        dtype=\"float32\"  # Use float32 for memory efficiency\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# Process the dataset in smaller batches\n",
        "batch_size = 32  # Adjust batch size as needed\n",
        "processed_speech_commands_v1 = speech_commands_v1.map(\n",
        "    preprocess_function, remove_columns=[\"audio\", \"file\"], batched=True, batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Clear unused variables and call garbage collector\n",
        "del speech_commands_v1\n",
        "gc.collect()\n",
        "\n",
        "# Load the dataset splits as a dict of numpy arrays\n",
        "train = processed_speech_commands_v1[\"train\"].shuffle(seed=42).with_format(\"numpy\")[:]\n",
        "test = processed_speech_commands_v1[\"test\"].shuffle(seed=42).with_format(\"numpy\")[:]\n",
        "\n",
        "# Clear processed dataset to free up memory\n",
        "del processed_speech_commands_v1\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVrHkyXBkyao"
      },
      "source": [
        "## Defining the Wav2Vec 2.0 with Classification-Head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GevGu3xKkyao"
      },
      "source": [
        "We now define our model. To be precise, we define a Wav2Vec 2.0 model and add a\n",
        "Classification-Head on top to output a probability distribution of all classes for each\n",
        "input audio sample. Since the model might get complex we first define the Wav2Vec\n",
        "2.0 model with Classification-Head as a Keras layer and then build the model using that.\n",
        "\n",
        "We instantiate our main Wav2Vec 2.0 model using the `TFWav2Vec2Model` class. This will\n",
        "instantiate a model which will output 768 or 1024 dimensional embeddings according to\n",
        "the config you choose (BASE or LARGE). The `from_pretrained()` additionally helps you\n",
        "load pre-trained weights from the Hugging Face Model Hub. It will download the pre-trained weights\n",
        "together with the config corresponding to the name of the model you have mentioned when\n",
        "calling the method. For our task, we choose the BASE variant of the model that has\n",
        "just been pre-trained, since we fine-tune over it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F2wuP2BXkyap"
      },
      "outputs": [],
      "source": [
        "from transformers import TFWav2Vec2Model\n",
        "\n",
        "\n",
        "def mean_pool(hidden_states, feature_lengths):\n",
        "    attenion_mask = tf.sequence_mask(\n",
        "        feature_lengths, maxlen=MAX_FRAMES, dtype=tf.dtypes.int64\n",
        "    )\n",
        "    padding_mask = tf.cast(\n",
        "        tf.reverse(tf.cumsum(tf.reverse(attenion_mask, [-1]), -1), [-1]),\n",
        "        dtype=tf.dtypes.bool,\n",
        "    )\n",
        "    hidden_states = tf.where(\n",
        "        tf.broadcast_to(\n",
        "            tf.expand_dims(~padding_mask, -1), (BATCH_SIZE, MAX_FRAMES, HIDDEN_DIM)\n",
        "        ),\n",
        "        0.0,\n",
        "        hidden_states,\n",
        "    )\n",
        "    pooled_state = tf.math.reduce_sum(hidden_states, axis=1) / tf.reshape(\n",
        "        tf.math.reduce_sum(tf.cast(padding_mask, dtype=tf.dtypes.float32), axis=1),\n",
        "        [-1, 1],\n",
        "    )\n",
        "    return pooled_state\n",
        "\n",
        "\n",
        "class TFWav2Vec2ForAudioClassification(layers.Layer):\n",
        "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
        "\n",
        "    def __init__(self, model_checkpoint, num_classes):\n",
        "        super().__init__()\n",
        "        # Instantiate the Wav2Vec 2.0 model without the Classification-Head\n",
        "        self.wav2vec2 = TFWav2Vec2Model.from_pretrained(\n",
        "            model_checkpoint, apply_spec_augment=False, from_pt=True\n",
        "        )\n",
        "        self.pooling = layers.GlobalAveragePooling1D()\n",
        "        # Drop-out layer before the final Classification-Head\n",
        "        self.intermediate_layer_dropout = layers.Dropout(0.5)\n",
        "        # Classification-Head\n",
        "        self.final_layer = layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # We take only the first output in the returned dictionary corresponding to the\n",
        "        # output of the last layer of Wav2vec 2.0\n",
        "        hidden_states = self.wav2vec2(inputs[\"input_values\"])[0]\n",
        "\n",
        "        # If attention mask does exist then mean-pool only un-masked output frames\n",
        "        if tf.is_tensor(inputs[\"attention_mask\"]):\n",
        "            # Get the length of each audio input by summing up the attention_mask\n",
        "            # (attention_mask = (BATCH_SIZE x MAX_SEQ_LENGTH) ∈ {1,0})\n",
        "            audio_lengths = tf.cumsum(inputs[\"attention_mask\"], -1)[:, -1]\n",
        "            # Get the number of Wav2Vec 2.0 output frames for each corresponding audio input\n",
        "            # length\n",
        "            feature_lengths = self.wav2vec2.wav2vec2._get_feat_extract_output_lengths(\n",
        "                audio_lengths\n",
        "            )\n",
        "            pooled_state = mean_pool(hidden_states, feature_lengths)\n",
        "        # If attention mask does not exist then mean-pool only all output frames\n",
        "        else:\n",
        "            pooled_state = self.pooling(hidden_states)\n",
        "\n",
        "        intermediate_state = self.intermediate_layer_dropout(pooled_state)\n",
        "        final_state = self.final_layer(intermediate_state)\n",
        "\n",
        "        return final_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDkgBZo4kyap"
      },
      "source": [
        "## Building and Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3583r7nkyap"
      },
      "source": [
        "We now build and compile our model. We use the `SparseCategoricalCrossentropy`\n",
        "to train our model since it is a classification task. Following much of literature\n",
        "we evaluate our model on the `accuracy` metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKWEBBC9kyap",
        "outputId": "ad3cc4ea-635f-4afc-e594-58afdb658399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "TFWav2Vec2Model has backpropagation operations that are NOT supported on CPU. If you wish to train/fine-tune this model, you need a GPU or a TPU\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFWav2Vec2Model: ['project_hid.weight', 'project_q.weight', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_hid.bias', 'quantizer.weight_proj.weight']\n",
            "- This IS expected if you are initializing TFWav2Vec2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFWav2Vec2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFWav2Vec2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWav2Vec2Model for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_model():\n",
        "    # Model's input\n",
        "    inputs = {\n",
        "        \"input_values\": tf.keras.Input(shape=(MAX_SEQ_LENGTH,), dtype=\"float32\"),\n",
        "        \"attention_mask\": tf.keras.Input(shape=(MAX_SEQ_LENGTH,), dtype=\"int32\"),\n",
        "    }\n",
        "    # Instantiate the Wav2Vec 2.0 model with Classification-Head using the desired\n",
        "    # pre-trained checkpoint\n",
        "    wav2vec2_model = TFWav2Vec2ForAudioClassification(MODEL_CHECKPOINT, NUM_CLASSES)(\n",
        "        inputs\n",
        "    )\n",
        "    # Model\n",
        "    model = tf.keras.Model(inputs, wav2vec2_model)\n",
        "    # Loss\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    # Optimizer\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    # Compile and return\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mTEYYWpkyap"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Before we start training our model, we divide the inputs into its\n",
        "dependent and independent variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "U35A4AREkyaq",
        "outputId": "4981b165-8ca2-485d-9a1d-7e8c163c3471"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a6bfb769f1e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove targets from training dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "# Remove targets from training dictionaries\n",
        "train_x = {x: y for x, y in train.items() if x != \"label\"}\n",
        "test_x = {x: y for x, y in test.items() if x != \"label\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdBzXD6Wkyaq"
      },
      "source": [
        "And now we can finally start training our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BQEUMU_Pkyaq",
        "outputId": "e793cf62-2310-498c-c4ef-6b3568139392"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a24b706783b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_x,\n",
        "    train[\"label\"],\n",
        "    validation_data=(test_x, test[\"label\"]),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=MAX_EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxmnTCBDkyaq"
      },
      "source": [
        "Great! Now that we have trained our model, we predict the classes\n",
        "for audio samples in the test set using the `model.predict()` method! We see\n",
        "the model predictions are not that great as it has been trained on a very small\n",
        "number of samples for just 1 epoch. For best results, we recommend training on\n",
        "the complete dataset for at least 5 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJZ4YqWQkyaq"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9mXjemIkyaq"
      },
      "source": [
        "Now we try to infer the model we trained on a randomly sampled audio file.\n",
        "We hear the audio file and then also see how well our model was able to predict!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2lXmvJokyaq"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "rand_int = random.randint(0, len(test_x))\n",
        "\n",
        "ipd.Audio(data=np.asarray(test_x[\"input_values\"][rand_int]), autoplay=True, rate=16000)\n",
        "\n",
        "print(\"Original Label is \", id2label[str(test[\"label\"][rand_int])])\n",
        "print(\"Predicted Label is \", id2label[str(np.argmax((preds[rand_int])))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFrCJ-dBkyaq"
      },
      "source": [
        "Now you can push this model to Hugging Face Model Hub and also share it with all your friends,\n",
        "family, favorite pets: they can all load it with the identifier\n",
        "`\"your-username/the-name-you-picked\"`, for instance:\n",
        "\n",
        "```python\n",
        "model.push_to_hub(\"wav2vec2-ks\", organization=\"keras-io\")\n",
        "tokenizer.push_to_hub(\"wav2vec2-ks\", organization=\"keras-io\")\n",
        "```\n",
        "And after you push your model this is how you can load it in the future!\n",
        "\n",
        "```python\n",
        "from transformers import TFWav2Vec2Model\n",
        "\n",
        "model = TFWav2Vec2Model.from_pretrained(\"your-username/my-awesome-model\", from_pt=True)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wav2vec2_audiocls",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c95121c4820229e40183c12cf809add4657f5d8cdc20fb3d24f9d7a7ade02504"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}